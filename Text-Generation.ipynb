{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOWoXN1MbO399dX0p+e4zk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajni0829/AIbyMyCap/blob/master/Text-Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QxV-tiXQbk5R"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import scipy\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import numpy\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from pandas.plotting import scatter_matrix\n",
        "from matplotlib import pyplot as pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('frankenstein-2.txt').read()"
      ],
      "metadata": {
        "id": "Nrabuu8nbmom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize.api import TokenizerI\n",
        "def tokenize_words(input):\n",
        "  input = input.lower()\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(input)\n",
        "  filtered = filter(lambda token: token not in stopwords.words('english'),tokens)\n",
        "  return \"\".join(filtered)\n",
        "\n",
        "processed_inputs = tokenize_words(file)\n"
      ],
      "metadata": {
        "id": "3dTPsuc4bmrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(processed_inputs)))\n",
        "char_to_num = dict((c,i) for i,c in enumerate(chars))"
      ],
      "metadata": {
        "id": "mKd-dByfpgrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print(input_len)\n",
        "print(vocab_len)"
      ],
      "metadata": {
        "id": "e4jqP14bbmua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "metadata": {
        "id": "yH9I26dgbmx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, input_len - seq_length, 1):\n",
        "  in_seq = processed_inputs[i:i+seq_length]\n",
        "  out_seq = processed_inputs[i+seq_length]\n",
        "  x_data.append([char_to_num[char] for char in in_seq])\n",
        "  y_data.append(char_to_num[out_seq])\n",
        "\n",
        "n_patterns = len(x_data)\n",
        "print(n_patterns)\n",
        "\n"
      ],
      "metadata": {
        "id": "_puGiyzKffmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = numpy.reshape(x_data,(n_patterns,seq_length,1))\n",
        "X = X/float(vocab_len)"
      ],
      "metadata": {
        "id": "QaWjpcHmffqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np_utils.to_categorical(y_data)"
      ],
      "metadata": {
        "id": "mdbGgTvMjIxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256,input_shape=(X.shape[1],X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1],activation='softmax'))"
      ],
      "metadata": {
        "id": "1_z3Jm6vjI1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam')\n"
      ],
      "metadata": {
        "id": "bLFCNfTLngg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"model_weights_saved.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose = 1, save_best_only=True,mode='min')\n",
        "desired_callbacks = [checkpoint]"
      ],
      "metadata": {
        "id": "SFirH2_gnglM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=4, batch_size=256,callbacks=desired_callbacks)"
      ],
      "metadata": {
        "id": "b0qqNWqCoo0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"model_weights_saved.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam')"
      ],
      "metadata": {
        "id": "m-mVL244oo4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_to_char = dict((i,c) for i,c in enumerate(chars))"
      ],
      "metadata": {
        "id": "RSheevhtrQK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = numpy.random.randint(0,len(x_data) - 1)\n",
        "pattern = x_data(start)\n",
        "print(''.join([num_to_char[value] for value in pattern]))"
      ],
      "metadata": {
        "id": "2Ur_BlsArQk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "   x = numpy.reshape(pattern, (1,len(pattern), 1))\n",
        "   x = x/float(vocab_len)\n",
        "   prediction = model_predict(x,verbose=0)\n",
        "   index = numpy.argmax(prediction)\n",
        "   result = num_to_char[index]\n",
        "   seq_in = [num_to_char[value] for value in pattern]\n",
        "   sys.stdout.write(result)\n",
        "   pattern.append(index)\n",
        "   pattern = pattern[1:len(pattern)]"
      ],
      "metadata": {
        "id": "xxfNIrCbsJBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t818I4Bmwh6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}